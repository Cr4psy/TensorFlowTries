{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc, os, csv, random, math\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AC\n",
    "#trainImagePath='C:/Users/ANTHO/Desktop/TestTensorFlow/KAGGLE/Dataset/imgpp/'\n",
    "#labelsPath = 'C:/Users/ANTHO/Desktop/TestTensorFlow/KAGGLE/Dataset/GT/'\n",
    "\n",
    "# VSP\n",
    "#trainImagePath='/Users/valurpalmarsson/Documents/DeepLearning/imgpp/'\n",
    "#labelsPath = '/Users/valurpalmarsson/Documents/DeepLearning/GT/'\n",
    "\n",
    "trainImagePath='./Dataset/imgpp/'\n",
    "labelsPath = './Dataset/GT/'\n",
    "\n",
    "mainPath='./Measure'\n",
    "\n",
    "epochs=5\n",
    "batchSize=10\n",
    "learningRate=1e-4\n",
    "numImg = 200 # Number of images to Load\n",
    "shuffleData = False # Shuffle data\n",
    "\n",
    "# Size of each subset as precentage of entire dataset\n",
    "trainSize=0.5\n",
    "valSize=0.25\n",
    "testSize=0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "./Measure0\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(path))\n",
    "\n",
    "path = mainPath\n",
    "i=0\n",
    "while os.path.exists(path):\n",
    "    path = mainPath+str(i)\n",
    "    i=i+1\n",
    "    print(path)\n",
    "\n",
    "os.makedirs(path)\n",
    "os.makedirs(path+'/Tensorboard')\n",
    "os.makedirs(path+'/SaveModel')\n",
    "os.makedirs(path+'/Results')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the images & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all the file in the folder\n",
    "fileNames = os.listdir(trainImagePath)\n",
    "\n",
    "# select a subset of files\n",
    "fileNames = fileNames[:numImg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 196608)\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#Extract all the image flatten and write them in an array\n",
    "imgs=[] # Init image list\n",
    "labels=[] # \n",
    "for fileName in fileNames: \n",
    "    \n",
    "    # Load images\n",
    "    img = scipy.misc.imread(trainImagePath+fileName, False,'RGB')     \n",
    "    img = img.ravel()#Flatten the image\n",
    "    imgs.append(img)\n",
    "    \n",
    "    # Load labels\n",
    "    labelName = fileName.partition('pp')[0]+'GT.csv'\n",
    "    with open(labelsPath+labelName, 'r') as f:#Read the file\n",
    "        reader = csv.reader(f)\n",
    "        label= np.asarray(list(reader), dtype=float)#Extract the value in an array\n",
    "        label = label.ravel()#flatten\n",
    "        labels.append(label)#Add to the list\n",
    "        \n",
    "imgs=np.matrix(imgs, dtype=float)/255\n",
    "labels = np.matrix(labels, dtype=float)#Convert to a matrix\n",
    "    \n",
    "#Size(nbImage, nbPixel)\n",
    "print(imgs.shape)\n",
    "print(len(imgs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select size of train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates train, validate and test subsets from the loaded images\n",
    "# Can shuffle the images by using the boolean input argument shuffle\n",
    "def createDatasets(imgs,labels,trainSize,valSize,testSize,shuffle):\n",
    "\n",
    "    # Get number of images\n",
    "    numImg = len(imgs) \n",
    "    \n",
    "    # Indexes used to split the entire dataset into subsets\n",
    "    indx1 = int(numImg*trainSize)\n",
    "    indx2 = int(numImg*(trainSize+valSize))\n",
    "    \n",
    "    if shuffle:\n",
    "        # Shuffle images to a random order, (shuffles imgs and labels in the same random order)\n",
    "        combined = list(zip(imgs, labels))\n",
    "        random.shuffle(combined)\n",
    "        imgs[:], labels[:] = zip(*combined)\n",
    "\n",
    "    # Training subset\n",
    "    imgsTrain = imgs[0:indx1]\n",
    "    labelsHotTrain = labels[0:indx1]\n",
    "\n",
    "    # Validation subset\n",
    "    imgsValidate = imgs[indx1:indx2]\n",
    "    labelsHotValidate = labels[indx1:indx2]\n",
    "\n",
    "    # Test subset\n",
    "    imgsTest = imgs[indx2:]\n",
    "    labelsHotTest = labels[indx2:]\n",
    "    \n",
    "    # Return the subsets as well as the corresponding ground-truth\n",
    "    return imgsTrain,labelsHotTrain,imgsValidate,labelsHotValidate,imgsTest,labelsHotTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PARAMETERS ##\n",
    "tensorBoard=True      #Save a summary?\n",
    "saveVariable=False     #Save the variabe?\n",
    "#retrieveSavedVariable=True #Retrieve saved variable?\n",
    "\n",
    "# Split dataset to subsets\n",
    "imgsTrain,labelsHotTrain,imgsValidate,labelsHotValidate,imgsTest,labelsHotTest = createDatasets(imgs,labels,trainSize,valSize,testSize,shuffleData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(imgs[0].shape)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    y = tf.reshape(labelsHotTest,[-1,43,43,1])\n",
    "    \n",
    "    y_pre = sess.run(prediction, feed_dict={xs: imgsTest})\n",
    "    y_pre = tf.cast(y_pre, tf.float32)#Force float32\n",
    "    \n",
    "    y_label = tf.reshape(labelsHotTest, [-1, 43, 43, 1])\n",
    "    y_label = tf.cast(y_label, tf.float32)\n",
    "    \n",
    "    summa = tf.reduce_sum(y,0)\n",
    "    summavec = tf.reshape(summa,[-1])\n",
    "    \n",
    "    #print(y_pre)\n",
    "    print(y_label)\n",
    "    print(y_pre)\n",
    "    #print(tf.metrics.mean_absolute_error(tf.reduce_sum(y_pre,[1,2]),tf.reduce_sum(y_label,[1,2])))\n",
    "    #print(tf.reduce_mean(tf.square(tf.reduce_max(tf.subtract(y_pre,y_label),[1,2]))))\n",
    "    #print(tf.reduce_sum(y_label,[1,2]),tf.reduce_sum(y_pre,[1,2]))\n",
    "    diff = tf.subtract(tf.reduce_sum(y_label,[1,2]),tf.reduce_sum(y_pre,[1,2]))\n",
    "    print(tf.sqrt(tf.reduce_mean(tf.square(diff))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function\n",
    "\n",
    "def evaluateNetwork(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs}) # Forward pass using v_xs as input to network\n",
    "    y_pre = tf.cast(y_pre, tf.float32) # Force float32 \n",
    "    result = tf.reduce_sum(y_pre) # Integrate over density map to get estimated sea lion count\n",
    "    return result\n",
    "\n",
    "# Calculate mean absolute error (MAE) and mean square error (MSE) for evaluation\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_label = tf.reshape(v_ys, [-1, 43, 43, 1])\n",
    "    y_label = tf.cast(y_label, tf.float32)\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    y_pre = tf.cast(y_pre, tf.float32)#Force float32\n",
    "    #correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    diff = tf.subtract(tf.reduce_sum(y_label,[1,2]),tf.reduce_sum(y_pre,[1,2]))\n",
    "    accuracyMAE = tf.cast(tf.reduce_mean(tf.abs(diff)),tf.float32)\n",
    "    accuracyMSE = tf.cast(tf.sqrt(tf.reduce_mean(tf.square(diff))),tf.float32)\n",
    "    MAE = sess.run(accuracyMAE, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    MSE = sess.run(accuracyMSE, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    \n",
    "    return MAE,MSE\n",
    "\n",
    "def weight_variable(shape, nameIn):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=nameIn)\n",
    "\n",
    "def bias_variable(shape, nameIn):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=nameIn)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def max_pool_3x3(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,3,3,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "\n",
    "## Input layer ##\n",
    "with tf.name_scope(\"Input\") as scope:\n",
    "    # define placeholder for inputs to network\n",
    "    xs = tf.placeholder(tf.float32, [None, imgs.shape[1]])   # 256x256x3\n",
    "    ys = tf.placeholder(tf.float32, [None, labels.shape[1]]) #43x43 \n",
    "    x_image = tf.reshape(xs, [-1, 256, 256, 3])#[batch, in_depth, in_height, in_width, in_channels].\n",
    "    y_label = tf.reshape(ys, [-1, 43, 43, 1])\n",
    "    #print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "    \n",
    "## conv1 layer ##\n",
    "## maxpooling 2x2 ##\n",
    "#20x (7x7)\n",
    "patch=7\n",
    "sizeIn=3\n",
    "sizeOut=20\n",
    "with tf.name_scope(\"Conv1\") as scope:\n",
    "    W_conv1 = weight_variable([patch,patch, sizeIn,sizeOut], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([sizeOut], \"b_conv1\")\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1) #Maxpooling 2x2, output size= inout size/2\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv1 = tf.summary.histogram(\"weightsConv1\", W_conv1)\n",
    "    b_h_conv1 = tf.summary.histogram(\"biasesConv1\", b_conv1)\n",
    "    \n",
    "## conv2 layer ##\n",
    "## maxpooling 3x3 ##\n",
    "#40x (5x5)\n",
    "patch=5\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=40\n",
    "with tf.name_scope(\"Conv2\") as scope:\n",
    "    W_conv2 = weight_variable([patch,patch, sizeIn,sizeOut],\"W_conv2\")\n",
    "    b_conv2 = bias_variable([sizeOut],\"b_conv2\")\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_3x3(h_conv2) #Maxpooling 3x3, output size= inout size/3\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv2 = tf.summary.histogram(\"weightsConv2\", W_conv2)\n",
    "    b_h_conv2 = tf.summary.histogram(\"biasesConv2\", b_conv2)\n",
    "    \n",
    "## conv3 layer ##\n",
    "#20x (5x5)\n",
    "patch=5\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=20\n",
    "with tf.name_scope(\"Conv3\") as scope:\n",
    "    W_conv3 = weight_variable([patch,patch, sizeIn,sizeOut],\"W_conv3\")\n",
    "    b_conv3 = bias_variable([sizeOut],\"b_conv3\")\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv3 = tf.summary.histogram(\"weightsConv3\", W_conv3)\n",
    "    b_h_conv3 = tf.summary.histogram(\"biasesConv3\", b_conv3)\n",
    "    \n",
    "## conv4 layer ##\n",
    "#10x (5x5)\n",
    "patch=5\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=10\n",
    "with tf.name_scope(\"Conv4\") as scope:\n",
    "    W_conv4 = weight_variable([patch,patch, sizeIn,sizeOut],\"W_conv4\")\n",
    "    b_conv4 = bias_variable([sizeOut],\"b_conv4\")\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4) + b_conv4)\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv4 = tf.summary.histogram(\"weightsConv4\", W_conv4)\n",
    "    b_h_conv4 = tf.summary.histogram(\"biasesConv4\", b_conv4)\n",
    "    \n",
    "## conv5 layer ##\n",
    "#1x (1x1)\n",
    "patch=1\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=1\n",
    "with tf.name_scope(\"Conv5\") as scope:\n",
    "    W_conv5 = weight_variable([patch,patch, sizeIn,sizeOut], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([sizeOut], \"b_conv5\")\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5) + b_conv5)\n",
    "    #h_conv5 = conv2d(h_conv4, W_conv5) + b_conv5\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv5 = tf.summary.histogram(\"weightsConv5\", W_conv5)\n",
    "    b_h_conv5 = tf.summary.histogram(\"biasesConv5\", b_conv5)\n",
    "    \n",
    "   \n",
    " ## Prediction ##\n",
    "with tf.name_scope(\"prediction\") as scope:\n",
    "    prediction = h_conv5\n",
    "    #img_prediction = tf.summary.image(\"densitymap\", prediction)\n",
    "\n",
    "\n",
    "## Loss function ##\n",
    "# the error between prediction and real data\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),reduction_indices=[1]))# loss\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    loss = tf.reduce_mean(tf.square(tf.reduce_max(tf.subtract(prediction,y_label),[1,2])))\n",
    "    #cross_entropy = tf.reshape(tf.reduce_sum(tf.square((tf.subtract(prediction, y_label))),0),[-1])#Euclidean distance\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.AdamOptimizer(learningRate).minimize(loss)\n",
    "    #train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bla, (1, 196608)\n"
     ]
    }
   ],
   "source": [
    "print('Bla,',imgsTest[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Training MAE and MSE:  8.5983 24.0439\n",
      "Validation MAE and MSE:  3.52073 7.98764\n",
      "Epoch:  2\n",
      "Training MAE and MSE:  8.6 24.045\n",
      "Validation MAE and MSE:  3.51958 7.98855\n",
      "Epoch:  3\n",
      "Training MAE and MSE:  8.6 24.045\n",
      "Validation MAE and MSE:  3.51967 7.9891\n",
      "Epoch:  4\n",
      "Training MAE and MSE:  8.6 24.045\n",
      "Validation MAE and MSE:  3.51973 7.98926\n",
      "Epoch:  5\n",
      "Training MAE and MSE:  8.6 24.045\n",
      "Validation MAE and MSE:  3.51976 7.98933\n",
      "Test MAE and MSE:  2.36 6.02329\n"
     ]
    }
   ],
   "source": [
    "## INITIALISATION ##\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    \n",
    "## TENSOR BOARD ##\n",
    "if tensorBoard:\n",
    "    # Merge all summaries into a single operator\n",
    "    merged_summary_op = tf.summary.merge_all() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    ### SAVE DATA ###\n",
    "    if saveVariable:\n",
    "        saver = tf.train.Saver()\n",
    " \n",
    "    ### TENSORBOARD ###\n",
    "    if tensorBoard:\n",
    "        # Folder where the data are saved\n",
    "        summary_writer = tf.summary.FileWriter(path+'/TensorBoard/', sess.graph)\n",
    "\n",
    "\n",
    "    if int(len(imgs)) < batchSize:#If there are less data than the batch size\n",
    "        nbBatch=1\n",
    "    else:\n",
    "        nbBatch=int((len(imgsTrain))/batchSize)\n",
    "    \n",
    "    # Init variables \n",
    "    trainMAE =  [0 for x in range(epochs)]\n",
    "    validateMAE =  [0 for x in range(epochs)]\n",
    "    trainMSE =  [0 for x in range(epochs)]\n",
    "    validateMSE =  [0 for x in range(epochs)]\n",
    "    \n",
    "    #print(compute_accuracy(imgsTest,labelsHotTest))\n",
    "\n",
    "    #print(compute_accuracy(imgsTest, labelsHotTest))\n",
    "    for epoch in range(epochs):#Go through all the epochs\n",
    "        for batchNum in range(nbBatch):#Go through all the batches\n",
    "            #print(batchNum)\n",
    "            if batchSize==1:\n",
    "                batch_xs = imgsTrain[batchNum*batchSize]\n",
    "                batch_ys = labelsHotTrain[batchNum*batchSize]\n",
    "            else:\n",
    "                batch_xs = imgsTrain[batchNum*batchSize:(batchNum*batchSize+(batchSize))]\n",
    "                batch_ys = labelsHotTrain[batchNum*batchSize:(batchNum*batchSize+(batchSize))]\n",
    "                #print(len(batch_xs))\n",
    "            \n",
    "            sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        \n",
    "        print('Epoch: ',epoch+1)\n",
    "        \n",
    "        trainMAE[epoch],trainMSE[epoch] = compute_accuracy(imgsTrain, labelsHotTrain)\n",
    "        validateMAE[epoch],validateMSE[epoch] = compute_accuracy(imgsValidate, labelsHotValidate)\n",
    "        \n",
    "        print('Training MAE and MSE: ',trainMAE[epoch],trainMSE[epoch])\n",
    "        print('Validation MAE and MSE: ',validateMAE[epoch],validateMSE[epoch])\n",
    "        \n",
    "        ### TENSORBOARD ###\n",
    "        if tensorBoard:\n",
    "            summary_str = sess.run(merged_summary_op, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "            summary_writer.add_summary(summary_str, epoch)\n",
    "        ### SAVE DATA ###\n",
    "        if epoch%1==0:\n",
    "            if saveVariable:\n",
    "                saver.save(sess, path+'/SaveModel/cnnSave', global_step=epoch)\n",
    "    testMAE, testMSE = compute_accuracy(imgsTest, labelsHotTest)       \n",
    "    print('Test MAE and MSE: ',testMAE,testMSE)\n",
    "    \n",
    "    #Save the MAE and MSE of each epoch\n",
    "    np.savetxt(path+\"/Results/EpochMAEMSE.csv\", np.transpose([trainMAE, trainMSE, validateMAE, validateMSE]), delimiter=\",\")\n",
    "    np.savetxt(path+\"/Results/TESTMAEMSE.csv\", np.transpose([testMAE, testMSE]), delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRgKyq/yZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2691fb92748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot MAE and MSE during training\n",
    "\n",
    "plt.subplot(121) # MAE\n",
    "plt.plot(np.linspace(1,epochs,epochs),trainMAE,'b',label='train')\n",
    "plt.plot(np.linspace(1,epochs,epochs),validateMAE,'r',label='validation')\n",
    "plt.xlabel('Training time [epoch]')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['train','validation'])\n",
    "plt.title('Mean Absolute Error')\n",
    "\n",
    "plt.subplot(122) # MSE\n",
    "plt.plot(np.linspace(1,epochs,epochs),trainMSE,'b',label='train')\n",
    "plt.plot(np.linspace(1,epochs,epochs),validateMSE,'r',label='validation')\n",
    "plt.xlabel('Training time [epoch]')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['train','validation'])\n",
    "plt.title('Mean Square Error')\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+'/Results/graphs.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
