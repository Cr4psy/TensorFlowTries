{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc, os, csv, random, math\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorflow.contrib import learn\n",
    "#from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AC\n",
    "#trainImagePath='C:/Users/ANTHO/Desktop/TestTensorFlow/KAGGLE/Dataset/imgpp/'\n",
    "#labelsPath = 'C:/Users/ANTHO/Desktop/TestTensorFlow/KAGGLE/Dataset/GT/'\n",
    "\n",
    "# VSP\n",
    "trainImagePath='/Users/valurpalmarsson/Documents/DeepLearning/imgpp/'\n",
    "labelsPath = '/Users/valurpalmarsson/Documents/DeepLearning/GT/'\n",
    "\n",
    "#trainImagePath='./Dataset/imgpp/'\n",
    "#labelsPath = './Dataset/GT/'\n",
    "\n",
    "epochs=5\n",
    "batchSize=10\n",
    "learningRate=1e-4\n",
    "dropOutFactor=0.5\n",
    "numImg = 200 # Number of images to Load\n",
    "\n",
    "# Size of each subset as precentage of entire dataset\n",
    "trainSize=0.5\n",
    "valSize=0.25\n",
    "testSize=0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the images & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract all the file in the folder\n",
    "#listImage=check_output([\"ls\", \"Dataset/train\"]).decode(\"utf8\")\n",
    "fileNames = os.listdir(trainImagePath)\n",
    "#fileNames = sorted(fileNames, key=lambda \n",
    "#                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files\n",
    "fileNames = fileNames[:numImg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 196608)\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#Extract all the image flatten and write them in an array\n",
    "imgs=[] # Init image list\n",
    "labels=[] # \n",
    "for fileName in fileNames: \n",
    "    \n",
    "    # Load images\n",
    "    img = scipy.misc.imread(trainImagePath+fileName, False,'RGB')     \n",
    "    img = img.ravel()#Flatten the image\n",
    "    imgs.append(img)\n",
    "    \n",
    "    # Load labels\n",
    "    labelName = fileName.partition('pp')[0]+'GT.csv'\n",
    "    with open(labelsPath+labelName, 'r') as f:#Read the file\n",
    "        reader = csv.reader(f)\n",
    "        label= np.asarray(list(reader), dtype=float)#Extract the value in an array\n",
    "        label = label.ravel()#flatten\n",
    "        labels.append(label)#Add to the list\n",
    "        \n",
    "imgs=np.matrix(imgs, dtype=float)/255\n",
    "labels = np.matrix(labels, dtype=float)#Convert to a matrix\n",
    "    \n",
    "#Size(nbImage, nbPixel)\n",
    "print(imgs.shape)\n",
    "print(len(imgs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select size of train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates train, validate and test subsets from the loaded images\n",
    "# Can shuffle the images by using the boolean input argument shuffle\n",
    "def createDatasets(imgs,labels,trainSize,valSize,testSize,shuffle):\n",
    "\n",
    "    # Get number of images\n",
    "    numImg = len(imgs) \n",
    "    \n",
    "    # Indexes used to split the entire dataset into subsets\n",
    "    indx1 = int(numImg*trainSize)\n",
    "    indx2 = int(numImg*(trainSize+valSize))\n",
    "    \n",
    "    if shuffle:\n",
    "        # Shuffle images to a random order, (shuffles imgs and labels in the same random order)\n",
    "        combined = list(zip(imgs, labels))\n",
    "        random.shuffle(combined)\n",
    "        imgs[:], labels[:] = zip(*combined)\n",
    "\n",
    "    # Training subset\n",
    "    imgsTrain = imgs[0:indx1]\n",
    "    labelsHotTrain = labels[0:indx1]\n",
    "\n",
    "    # Validation subset\n",
    "    imgsValidate = imgs[indx1:indx2]\n",
    "    labelsHotValidate = labels[indx1:indx2]\n",
    "\n",
    "    # Test subset\n",
    "    imgsTest = imgs[indx2:]\n",
    "    labelsHotTest = labels[indx2:]\n",
    "    \n",
    "    # Return the subsets as well as the corresponding ground-truth\n",
    "    return imgsTrain,labelsHotTrain,imgsValidate,labelsHotValidate,imgsTest,labelsHotTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PARAMETERS ##\n",
    "tensorBoard=True      #Save a summary?\n",
    "saveVariable=False     #Save the variabe?\n",
    "#retrieveSavedVariable=True #Retrieve saved variable?\n",
    "\n",
    "# Split dataset to subsets\n",
    "imgsTrain,labelsHotTrain,imgsValidate,labelsHotValidate,imgsTest,labelsHotTest = createDatasets(imgs,labels,trainSize,valSize,testSize,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 196608)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function\n",
    "\n",
    "def evaluateNetwork(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs}) # Forward pass using v_xs as input to network\n",
    "    y_pre = tf.cast(y_pre, tf.float32) # Force float32 \n",
    "    result = tf.reduce_sum(y_pre) # Integrate over density map to get estimated sea lion count\n",
    "    return result\n",
    "\n",
    "# Calculate mean absolute error (MAE) and mean square error (MSE) for evaluation\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_label = tf.reshape(v_ys, [-1, 43, 43, 1])\n",
    "    y_label = tf.cast(y_label, tf.float32)\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    y_pre = tf.cast(y_pre, tf.float32)#Force float32\n",
    "    #correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy = tf.reduce_sum(tf.square((tf.subtract(y_pre,  y_label))))\n",
    "    #accuracy = tf.subtract((tf.reduce_sum(y_pre),tf.reduce_sum(y_label))\n",
    "    MAE = tf.reduce_sum(tf.abs(tf.subtract(y_pre,y_label)))\n",
    "    MSE = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return MSE\n",
    "\n",
    "def weight_variable(shape, nameIn):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=nameIn)\n",
    "\n",
    "def bias_variable(shape, nameIn):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=nameIn)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def max_pool_3x3(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,3,3,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Architecture\n",
    "\n",
    "## Input layer ##\n",
    "with tf.name_scope(\"Input\") as scope:\n",
    "    # define placeholder for inputs to network\n",
    "    xs = tf.placeholder(tf.float32, [None, imgs.shape[1]])   # 256x256x3\n",
    "    ys = tf.placeholder(tf.float32, [None, labels.shape[1]]) #43x43 \n",
    "    x_image = tf.reshape(xs, [-1, 256, 256, 3])#[batch, in_depth, in_height, in_width, in_channels].\n",
    "    y_label = tf.reshape(ys, [-1, 43, 43, 1])\n",
    "    # print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "    \n",
    "## conv1 layer ##\n",
    "## maxpooling 2x2 ##\n",
    "#20x (7x7)\n",
    "patch=7\n",
    "sizeIn=3\n",
    "sizeOut=20\n",
    "with tf.name_scope(\"Conv1\") as scope:\n",
    "    W_conv1 = weight_variable([patch,patch, sizeIn,sizeOut], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([sizeOut], \"b_conv1\")\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1) #Maxpooling 2x2, output size= inout size/2\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv1 = tf.summary.histogram(\"weightsConv1\", W_conv1)\n",
    "    b_h_conv1 = tf.summary.histogram(\"biasesConv1\", b_conv1)\n",
    "    \n",
    "## conv2 layer ##\n",
    "## maxpooling 3x3 ##\n",
    "#40x (5x5)\n",
    "patch=5\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=40\n",
    "with tf.name_scope(\"Conv2\") as scope:\n",
    "    W_conv2 = weight_variable([patch,patch, sizeIn,sizeOut],\"W_conv2\")\n",
    "    b_conv2 = bias_variable([sizeOut],\"b_conv2\")\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_3x3(h_conv2) #Maxpooling 3x3, output size= inout size/3\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv2 = tf.summary.histogram(\"weightsConv2\", W_conv2)\n",
    "    b_h_conv2 = tf.summary.histogram(\"biasesConv2\", b_conv2)\n",
    "    \n",
    "## conv3 layer ##\n",
    "#20x (5x5)\n",
    "patch=5\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=20\n",
    "with tf.name_scope(\"Conv3\") as scope:\n",
    "    W_conv3 = weight_variable([patch,patch, sizeIn,sizeOut],\"W_conv3\")\n",
    "    b_conv3 = bias_variable([sizeOut],\"b_conv3\")\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv3 = tf.summary.histogram(\"weightsConv3\", W_conv3)\n",
    "    b_h_conv3 = tf.summary.histogram(\"biasesConv3\", b_conv3)\n",
    "    \n",
    "## conv4 layer ##\n",
    "#10x (5x5)\n",
    "patch=5\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=10\n",
    "with tf.name_scope(\"Conv4\") as scope:\n",
    "    W_conv4 = weight_variable([patch,patch, sizeIn,sizeOut],\"W_conv4\")\n",
    "    b_conv4 = bias_variable([sizeOut],\"b_conv4\")\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4) + b_conv4)\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv4 = tf.summary.histogram(\"weightsConv4\", W_conv4)\n",
    "    b_h_conv4 = tf.summary.histogram(\"biasesConv4\", b_conv4)\n",
    "    \n",
    "## conv5 layer ##\n",
    "#1x (1x1)\n",
    "patch=1\n",
    "sizeIn=sizeOut #From previous ConvNet\n",
    "sizeOut=1\n",
    "with tf.name_scope(\"Conv5\") as scope:\n",
    "    W_conv5 = weight_variable([patch,patch, sizeIn,sizeOut], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([sizeOut], \"b_conv5\")\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5) + b_conv5)\n",
    "    #h_conv5 = conv2d(h_conv4, W_conv5) + b_conv5\n",
    "    # Add summary ops to collect data\n",
    "    w_h_conv5 = tf.summary.histogram(\"weightsConv5\", W_conv5)\n",
    "    b_h_conv5 = tf.summary.histogram(\"biasesConv5\", b_conv5)\n",
    "    \n",
    "   \n",
    " ## Prediction ##\n",
    "with tf.name_scope(\"prediction\") as scope:\n",
    "    prediction = h_conv5\n",
    "    img_prediction = tf.summary.image(\"densitymap\", prediction)\n",
    "\n",
    "\n",
    "## Loss function ##\n",
    "# the error between prediction and real data\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),reduction_indices=[1]))# loss\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    cross_entropy = tf.reduce_sum(tf.square((tf.subtract(prediction, y_label))))#Euclidean distance\n",
    "    tf.summary.scalar(\"cost_function\", cross_entropy)\n",
    "    \n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.AdamOptimizer(learningRate).minimize(cross_entropy)\n",
    "    #train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bla, (1, 196608)\n"
     ]
    }
   ],
   "source": [
    "print('Bla,',imgsTest[0].shape)\n",
    "#print(compute_accuracy(imgsTest,labelsHotTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Training MSE:  9333.28\n",
      "Validation MSE:  4748.38\n",
      "Epoch:  2\n",
      "Training MSE:  2042.21\n",
      "Validation MSE:  965.417\n",
      "Epoch:  3\n",
      "Training MSE:  1329.81\n",
      "Validation MSE:  593.54\n",
      "Epoch:  4\n",
      "Training MSE:  1123.32\n",
      "Validation MSE:  484.203\n",
      "Epoch:  5\n",
      "Training MSE:  1008.23\n",
      "Validation MSE:  423.754\n",
      "Test MSE:  534.615\n"
     ]
    }
   ],
   "source": [
    "## INITIALISATION ##\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    \n",
    "## TENSOR BOARD ##\n",
    "if tensorBoard:\n",
    "    # Merge all summaries into a single operator\n",
    "    merged_summary_op = tf.summary.merge_all() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    ### SAVE DATA ###\n",
    "    if saveVariable:\n",
    "        saver = tf.train.Saver()\n",
    " \n",
    "    ### TENSORBOARD ###\n",
    "    if tensorBoard:\n",
    "        # Folder where the data are saved\n",
    "        summary_writer = tf.summary.FileWriter('./Measure/V1/', sess.graph)\n",
    "\n",
    "\n",
    "    if int(len(imgs)) < batchSize:#If there are less data than the batch size\n",
    "        nbBatch=1\n",
    "    else:\n",
    "        nbBatch=int((len(imgsTrain))/batchSize)\n",
    "    \n",
    "    # Init variables \n",
    "    trainMSE =  [0 for x in range(epochs)]\n",
    "    validateMSE =  [0 for x in range(epochs)]\n",
    "\n",
    "    #print(compute_accuracy(imgsTest, labelsHotTest))\n",
    "    for epoch in range(epochs):#Go through all the epochs\n",
    "        for batchNum in range(nbBatch):#Go through all the batches\n",
    "            #print(batchNum)\n",
    "            if batchSize==1:\n",
    "                batch_xs = imgsTrain[batchNum*batchSize]\n",
    "                batch_ys = labelsHotTrain[batchNum*batchSize]\n",
    "            else:\n",
    "                batch_xs = imgsTrain[batchNum*batchSize:(batchNum*batchSize+(batchSize))]\n",
    "                batch_ys = labelsHotTrain[batchNum*batchSize:(batchNum*batchSize+(batchSize))]\n",
    "                #print(len(batch_xs))\n",
    "            \n",
    "            sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        \n",
    "        print('Epoch: ',epoch+1)\n",
    "        trainMSE[epoch] = compute_accuracy(imgsTrain, labelsHotTrain)\n",
    "        validateMSE[epoch] = compute_accuracy(imgsValidate, labelsHotValidate)\n",
    "        print('Training MSE: ',trainMSE[epoch])\n",
    "        print('Validation MSE: ',validateMSE[epoch])\n",
    "        \n",
    "        ### TENSORBOARD ###\n",
    "        #if tensorBoard:\n",
    "        #    summary_str = sess.run(merged_summary_op, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        #    summary_writer.add_summary(summary_str, i)\n",
    "        ### SAVE DATA ###\n",
    "        if epoch%1==0:\n",
    "            if saveVariable:\n",
    "                saver.save(sess, './Measure/cnnSave', global_step=i)\n",
    "            \n",
    "    print('Test MSE: ',compute_accuracy(imgsTest, labelsHotTest))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2R5m4Y4LNzcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bca94e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot MSE during training\n",
    "plt.plot(np.linspace(1,epochs,epochs),trainMSE,'b',label='train')\n",
    "plt.plot(np.linspace(1,epochs,epochs),validateMSE,'r',label='validation')\n",
    "plt.xlabel('Training time [epoch]')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['train','validation'])\n",
    "plt.title('Mean Square Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
